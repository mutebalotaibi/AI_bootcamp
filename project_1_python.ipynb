{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398f1be3",
   "metadata": {},
   "source": [
    "<h1><center> Name : Muteb Alotaibi</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fdc397",
   "metadata": {},
   "source": [
    "<h2>1. Data Reading:</h2>\n",
    "\n",
    "Write functions to read data from CSV, Excel, JSON, and other formats using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9867ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_file(file_path):\n",
    "    # Check if the file is a CSV or Excel file\n",
    "    if file_path.endswith('.csv'):\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith(('.xls', '.xlsx')):\n",
    "        # Read Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:   \n",
    "        print(\"Unsupported file format. Please provide a CSV or Excel file.\")\n",
    "        return None\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2ac935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file path: QVI_transaction_data.xlsx\n",
      "Data loaded successfully:\n",
      "         DATE  STORE_NBR  LYLTY_CARD_NBR  TXN_ID  PROD_NBR  \\\n",
      "0       43390          1            1000       1         5   \n",
      "1       43599          1            1307     348        66   \n",
      "2       43605          1            1343     383        61   \n",
      "3       43329          2            2373     974        69   \n",
      "4       43330          2            2426    1038       108   \n",
      "...       ...        ...             ...     ...       ...   \n",
      "264831  43533        272          272319  270088        89   \n",
      "264832  43325        272          272358  270154        74   \n",
      "264833  43410        272          272379  270187        51   \n",
      "264834  43461        272          272379  270188        42   \n",
      "264835  43365        272          272380  270189        74   \n",
      "\n",
      "                                       PROD_NAME  PROD_QTY  TOT_SALES  \n",
      "0         Natural Chip        Compny SeaSalt175g         2        6.0  \n",
      "1                       CCs Nacho Cheese    175g         3        6.3  \n",
      "2         Smiths Crinkle Cut  Chips Chicken 170g         2        2.9  \n",
      "3         Smiths Chip Thinly  S/Cream&Onion 175g         5       15.0  \n",
      "4       Kettle Tortilla ChpsHny&Jlpno Chili 150g         3       13.8  \n",
      "...                                          ...       ...        ...  \n",
      "264831   Kettle Sweet Chilli And Sour Cream 175g         2       10.8  \n",
      "264832             Tostitos Splash Of  Lime 175g         1        4.4  \n",
      "264833                  Doritos Mexicana    170g         2        8.8  \n",
      "264834   Doritos Corn Chip Mexican Jalapeno 150g         2        7.8  \n",
      "264835             Tostitos Splash Of  Lime 175g         2        8.8  \n",
      "\n",
      "[264836 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the file path: \")\n",
    "data = read_file(file_path)\n",
    "if data is not None:\n",
    "    print(\"Data loaded successfully:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac5bb6",
   "metadata": {},
   "source": [
    "<h2>2.Data Summary:</h2>\n",
    "Develop functions to print key statistical summaries of the data, including metrics like the average and most frequent values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7479d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_summary(data):\n",
    "  \n",
    "    summary = data.describe(include='all').transpose()\n",
    "    summary['dtype'] = data.dtypes\n",
    "    summary['missing_values'] = data.isnull().sum()\n",
    "    summary['unique_values'] = data.nunique()\n",
    "    return summary\n",
    "\n",
    "def correlation_matrix(data):\n",
    "   \n",
    "    return data.corr()\n",
    "\n",
    "def missing_values_summary(data):\n",
    "   \n",
    "    missing_values = data.isnull().sum()\n",
    "    return missing_values\n",
    "\n",
    "def categorical_summary(data):\n",
    "    \n",
    "    categorical_summary = data.describe(include=['object'])\n",
    "    return categorical_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8343746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   count unique                                     top  freq  \\\n",
      "DATE            264836.0    NaN                                     NaN   NaN   \n",
      "STORE_NBR       264836.0    NaN                                     NaN   NaN   \n",
      "LYLTY_CARD_NBR  264836.0    NaN                                     NaN   NaN   \n",
      "TXN_ID          264836.0    NaN                                     NaN   NaN   \n",
      "PROD_NBR        264836.0    NaN                                     NaN   NaN   \n",
      "PROD_NAME         264836    114  Kettle Mozzarella   Basil & Pesto 175g  3304   \n",
      "PROD_QTY        264836.0    NaN                                     NaN   NaN   \n",
      "TOT_SALES       264836.0    NaN                                     NaN   NaN   \n",
      "\n",
      "                         mean           std      min      25%       50%  \\\n",
      "DATE              43464.03626    105.389282  43282.0  43373.0   43464.0   \n",
      "STORE_NBR           135.08011      76.78418      1.0     70.0     130.0   \n",
      "LYLTY_CARD_NBR  135549.476404  80579.978022   1000.0  70021.0  130357.5   \n",
      "TXN_ID          135158.310815  78133.026026      1.0  67601.5  135137.5   \n",
      "PROD_NBR            56.583157     32.826638      1.0     28.0      56.0   \n",
      "PROD_NAME                 NaN           NaN      NaN      NaN       NaN   \n",
      "PROD_QTY             1.907309      0.643654      1.0      2.0       2.0   \n",
      "TOT_SALES              7.3042      3.083226      1.5      5.4       7.4   \n",
      "\n",
      "                      75%        max    dtype  missing_values  unique_values  \n",
      "DATE              43555.0    43646.0    int64               0            364  \n",
      "STORE_NBR           203.0      272.0    int64               0            272  \n",
      "LYLTY_CARD_NBR  203094.25  2373711.0    int64               0          72637  \n",
      "TXN_ID          202701.25  2415841.0    int64               0         263127  \n",
      "PROD_NBR             85.0      114.0    int64               0            114  \n",
      "PROD_NAME             NaN        NaN   object               0            114  \n",
      "PROD_QTY              2.0      200.0    int64               0              6  \n",
      "TOT_SALES             9.2      650.0  float64               0            112  \n"
     ]
    }
   ],
   "source": [
    "data_summery = dataset_summary(data)\n",
    "print (data_summery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e18825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    DATE  STORE_NBR  LYLTY_CARD_NBR    TXN_ID  PROD_NBR  \\\n",
      "DATE            1.000000   0.001314       -0.000014  0.001171 -0.004276   \n",
      "STORE_NBR       0.001314   1.000000        0.950869  0.997593  0.002309   \n",
      "LYLTY_CARD_NBR -0.000014   0.950869        1.000000  0.954919  0.001755   \n",
      "TXN_ID          0.001171   0.997593        0.954919  1.000000  0.002544   \n",
      "PROD_NBR       -0.004276   0.002309        0.001755  0.002544  1.000000   \n",
      "PROD_QTY       -0.001265   0.005295        0.003834  0.005343 -0.004813   \n",
      "TOT_SALES      -0.001681   0.003234        0.002908  0.003468 -0.133851   \n",
      "\n",
      "                PROD_QTY  TOT_SALES  \n",
      "DATE           -0.001265  -0.001681  \n",
      "STORE_NBR       0.005295   0.003234  \n",
      "LYLTY_CARD_NBR  0.003834   0.002908  \n",
      "TXN_ID          0.005343   0.003468  \n",
      "PROD_NBR       -0.004813  -0.133851  \n",
      "PROD_QTY        1.000000   0.715307  \n",
      "TOT_SALES       0.715307   1.000000  \n"
     ]
    }
   ],
   "source": [
    "data_coor= correlation_matrix(data)\n",
    "print (data_coor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48304c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE              0\n",
      "STORE_NBR         0\n",
      "LYLTY_CARD_NBR    0\n",
      "TXN_ID            0\n",
      "PROD_NBR          0\n",
      "PROD_NAME         0\n",
      "PROD_QTY          0\n",
      "TOT_SALES         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_missing = missing_values_summary(data)\n",
    "print(data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca23869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     PROD_NAME\n",
      "count                                   264836\n",
      "unique                                     114\n",
      "top     Kettle Mozzarella   Basil & Pesto 175g\n",
      "freq                                      3304\n"
     ]
    }
   ],
   "source": [
    "data_catigorical = categorical_summary(data)\n",
    "print(data_catigorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711b629",
   "metadata": {},
   "source": [
    "<h2>3.Handling Missing Values:</h2>\n",
    "Create functions for addressing missing values, offering solutions to either remove or impute them based on set strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, strategy='remove', **kwargs):\n",
    "  \n",
    "    if strategy == 'remove':\n",
    "        # Remove rows with any missing values\n",
    "        df_cleaned = df.dropna()\n",
    "        return df_cleaned\n",
    "    elif strategy in ['mean', 'median', 'mode']:\n",
    "        # Impute missing values with mean, median, or mode\n",
    "        if strategy == 'mean':\n",
    "            fill_value = df.mean()\n",
    "        elif strategy == 'median':\n",
    "            fill_value = df.median()\n",
    "        elif strategy == 'mode':\n",
    "            fill_value = df.mode().iloc[0]\n",
    "        \n",
    "        df_imputed = df.fillna(fill_value)\n",
    "        return df_imputed\n",
    "    elif strategy == 'constant':\n",
    "        # Impute missing values with a constant value\n",
    "        constant_value = kwargs.get('constant_value')\n",
    "        if constant_value is None:\n",
    "            print(\"Constant value not provided. Please provide a constant value.\")\n",
    "            return None\n",
    "        else:\n",
    "            df_imputed = df.fillna(constant_value)\n",
    "            return df_imputed\n",
    "    else:\n",
    "        print(\"Invalid strategy. Please choose one of the following strategies: 'remove', 'mean', 'median', 'mode', 'constant'.\")\n",
    "        return None\n",
    "\n",
    "data_check = {'First': [1, 3, 5,None],\n",
    "        'Second': [2,None, 4,6],\n",
    "        'thired': [3, 7, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Handle missing values using different strategies\n",
    "# Remove rows with missing values\n",
    "cleaned_df = handle_missing_values(df, strategy='remove')\n",
    "print(\"DataFrame after removing rows with missing values:\")\n",
    "print(cleaned_df)\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputed_mean_df = handle_missing_values(df, strategy='mean')\n",
    "print(\"\\nDataFrame after imputing missing values with mean:\")\n",
    "print(imputed_mean_df)\n",
    "\n",
    "# Impute missing values with a constant value (e.g., -1)\n",
    "imputed_constant_df = handle_missing_values(df, strategy='constant', constant_value=-1)\n",
    "print(\"\\nDataFrame after imputing missing values with a constant value (-1):\")\n",
    "print(imputed_constant_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b09e9b",
   "metadata": {},
   "source": [
    "<h2>4. Categorical Data Encoding:</h2>\n",
    " Design functions for encoding categorical data, allowing their conversion into numerical formats for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def label_encode_categorical(df, columns):\n",
    "    \"\"\"\n",
    "    Label encode categorical columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        columns (list): List of column names to label encode.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with categorical columns label encoded.\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df_encoded[col] = label_encoder.fit_transform(df[col])\n",
    "    return df_encoded\n",
    "\n",
    "def one_hot_encode_categorical(df, columns):\n",
    " \n",
    "    df_encoded = df.copy()\n",
    "    for col in columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df_encoded = pd.concat([df_encoded, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "            df_encoded.drop(col, axis=1, inplace=True)\n",
    "    return df_encoded\n",
    "\n",
    "# Example:\n",
    "data = {'Class': ['A', 'B', 'C'],\n",
    "        'Color': ['Red', 'Blue', 'Green'],\n",
    "        'Value': [10, 30, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Label encode categorical columns\n",
    "encoded_df_label = label_encode_categorical(df, columns=['Class', 'Color'])\n",
    "print(\"DataFrame after label encoding:\")\n",
    "print(encoded_df_label)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoded_df_one_hot = one_hot_encode_categorical(df, columns=['Class', 'Color'])\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(encoded_df_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd941d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
